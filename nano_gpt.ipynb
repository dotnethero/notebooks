{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTAGd/T4ZeoV90b1d2KmgT"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMqa0qPpB9aV",
        "outputId": "750ea4e0-8fbe-4988-b717-ca1ac87ac516"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (0.4.8)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax) (1.10.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from jax) (1.22.4)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax) (0.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (0.6.9)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.10/dist-packages (from flax) (1.22.4)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax) (0.1.36)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax) (6.0)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax) (13.3.4)\n",
            "Requirement already satisfied: jax>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from flax) (0.4.8)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from flax) (0.1.5)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from flax) (4.5.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax) (1.0.5)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax) (0.2.1)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.2->flax) (1.10.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.2->flax) (0.1.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.2->flax) (3.3.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax) (2.14.0)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax) (2.2.0)\n",
            "Requirement already satisfied: chex>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from optax->flax) (0.1.7)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.10/dist-packages (from optax->flax) (0.4.7+cuda11.cudnn86)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from optax->flax) (1.4.0)\n",
            "Requirement already satisfied: cached_property in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (1.5.2)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (1.5.6)\n",
            "Requirement already satisfied: etils in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (1.2.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (5.12.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.5->optax->flax) (0.12.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.5->optax->flax) (0.1.8)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=11.1->flax) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install jax\n",
        "!pip install flax"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szJbPb4dGlMO",
        "outputId": "59f38c1f-4336-4647-98e9-500cf6a116b0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-09 10:16:37--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-05-09 10:16:37 (26.2 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"input.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "vocab = sorted(list(set(text)))\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "print(vocab_size)\n",
        "print(''.join(vocab))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSEGnridG5ZX",
        "outputId": "2629d52a-c2bf-479c-8df0-d1bc16f5f91e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65\n",
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "itos = { i: s for i, s in enumerate(vocab) }\n",
        "stoi = { s: i for i, s in enumerate(vocab) }\n",
        "\n",
        "encode = lambda txt: [stoi[c] for c in txt ]\n",
        "decode = lambda num: ''.join([itos[n] for n in num ])\n",
        "\n",
        "encoded = encode(\"The test string\")\n",
        "decoded = decode(encoded)\n",
        "\n",
        "print(encoded)\n",
        "print(decoded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoszAc6nHkxW",
        "outputId": "b51376b3-a364-4191-c017-5aa3a1f2523a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[32, 46, 43, 1, 58, 43, 57, 58, 1, 57, 58, 56, 47, 52, 45]\n",
            "The test string\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import flax\n",
        "import optax\n",
        "\n",
        "from tqdm import tqdm\n",
        "from typing import Callable\n",
        "from jax import numpy as jnp\n",
        "from flax import linen as nn\n",
        "from functools import partial"
      ],
      "metadata": {
        "id": "YEml_yhcCF2m"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = jnp.array(encode(text))\n",
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loUgrT_wJWPM",
        "outputId": "0c9d6e49-9822-49b5-f941-884bf1618db7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1115394,)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_val = int(0.9 * len(data))\n",
        "train_data = data[:n_val]\n",
        "val_data = data[n_val:]\n",
        "\n",
        "train_data.shape, val_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPB6G1z8MB1N",
        "outputId": "f6f289e1-b3dd-43d0-9ad4-bfa536a625ef"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1003854,), (111540,))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "batch_size = 4\n",
        "n_embed = 32\n",
        "\n",
        "def get_batch(batch_key, *, split='train'):\n",
        "    d = train_data if split == 'train' else val_data\n",
        "    ix = jax.random.randint(batch_key, (batch_size,), 0, len(d)-block_size)\n",
        "    x = jnp.stack([d[i:i+block_size] for i in ix])\n",
        "    y = jnp.stack([d[i+1:i+block_size+1] for i in ix])\n",
        "    return x, y\n",
        "\n",
        "key = jax.random.PRNGKey(1337)\n",
        "\n",
        "X, Y = get_batch(key)\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDWSOGMuN3v0",
        "outputId": "4e5905d6-15f0-4a96-c633-b88f3c0e3e55"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 8)\n",
            "(4, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionHead(nn.Module):\n",
        "\n",
        "    wq_init: Callable = nn.initializers.lecun_normal()\n",
        "    wk_init: Callable = nn.initializers.lecun_normal()\n",
        "    wv_init: Callable = nn.initializers.lecun_normal()\n",
        "    \n",
        "    head_size: int = 32\n",
        "    \n",
        "    @nn.compact\n",
        "    def __call__(self, inputs):\n",
        "        \n",
        "        B, T, C = inputs.shape\n",
        "\n",
        "        # mask\n",
        "        ones = jnp.ones(shape=(T, T))\n",
        "        tril = jnp.tril(ones)\n",
        "        tril = jnp.stack([tril] * B)\n",
        "        \n",
        "        WQ = self.param(\"WQ\", self.wq_init, (C, self.head_size))\n",
        "        WK = self.param(\"WK\", self.wk_init, (C, self.head_size))\n",
        "        WV = self.param(\"WV\", self.wv_init, (C, self.head_size))\n",
        "        \n",
        "        Q = inputs @ WQ\n",
        "        K = inputs @ WK\n",
        "        V = inputs @ WV\n",
        "\n",
        "        KT = K.transpose([0, 2, 1]) # B, H, T\n",
        "        QK = Q @ KT / jnp.sqrt(self.head_size)\n",
        "        QK = jax.lax.select(tril == 0, jax.lax.broadcast(jnp.NINF, QK.shape), QK)\n",
        "\n",
        "        attention = nn.softmax(QK, axis=-1) @ V\n",
        "\n",
        "        return attention\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    head_number: int = 4\n",
        "    head_size: int = 32 // 4\n",
        "\n",
        "    def setup(self):\n",
        "        self.heads = [AttentionHead(head_size=self.head_size) for i in range(self.head_number)]\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        results = [h(inputs) for h in self.heads]\n",
        "        return jnp.concatenate(results, axis=-1)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "\n",
        "    features: int\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, inputs):\n",
        "        x = inputs\n",
        "        x = nn.Dense(self.features)(x)\n",
        "        x = nn.relu(x)\n",
        "        return x\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "    \n",
        "    vocab_size: int\n",
        "    block_size: int\n",
        "    embedding_size: int\n",
        "    head_number: int = 4\n",
        "\n",
        "    def setup(self):\n",
        "        self.token_embedding = nn.Embed(num_embeddings=self.vocab_size, features=self.embedding_size)\n",
        "        self.position_embedding = nn.Embed(num_embeddings=self.block_size, features=self.embedding_size)\n",
        "        self.sa_heads = MultiHeadAttention(head_number=self.head_number, head_size=self.embedding_size // self.head_number)\n",
        "        self.ffn = FeedForward(features=self.embedding_size)\n",
        "        self.lm_head = nn.Dense(self.vocab_size)\n",
        "    \n",
        "    def __call__(self, idx):\n",
        "        token_embeddings = self.token_embedding(idx) # B, T, C\n",
        "\n",
        "        positions = jnp.arange(0, self.block_size)\n",
        "        positions_embeddings = self.position_embedding(positions) # T, C\n",
        "\n",
        "        embeddings = token_embeddings + positions_embeddings\n",
        "        attention = self.sa_heads(embeddings)\n",
        "        attention = self.ffn(attention)\n",
        "        logits = self.lm_head(attention)\n",
        "\n",
        "        return logits\n",
        "\n",
        "@jax.jit\n",
        "def bigram_loss(y_hat, y):\n",
        "    losses = optax.softmax_cross_entropy_with_integer_labels(y_hat, y)\n",
        "    return jnp.mean(losses)\n",
        "\n",
        "def bigram_generate(apply_fn: Callable, key, idx, max_tokens=1):\n",
        "    for i in range(max_tokens):\n",
        "        key_i = jax.random.fold_in(key, i)\n",
        "        logits = apply_fn(params, idx[:, -block_size:])\n",
        "        logits = logits[:, -1, :] # B, C\n",
        "        probs = nn.softmax(logits, axis=-1) # B, C\n",
        "        idx_next = jax.random.categorical(key_i, logits, axis=-1) # B\n",
        "        idx_next = jnp.expand_dims(idx_next, -1)\n",
        "        idx = jnp.concatenate([idx, idx_next], axis=1) # B, T+1\n",
        "    return idx\n",
        "\n",
        "@partial(jax.jit, static_argnums=[0])\n",
        "def train_step(apply_fn: Callable, params, opt_state, x_batch, y_batch):\n",
        "\n",
        "    @jax.jit\n",
        "    def loss_fn(params, x_batch, y_batch):\n",
        "        y_hat = apply_fn(params, x_batch)\n",
        "        return bigram_loss(y_hat, y_batch)\n",
        "\n",
        "    loss, grad = jax.value_and_grad(loss_fn)(params, x_batch, y_batch)\n",
        "    updates, opt_state = opt.update(grad, opt_state)\n",
        "    params = optax.apply_updates(params, updates)\n",
        "    return params, opt_state, loss\n"
      ],
      "metadata": {
        "id": "odzKm4ItQSd5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key = jax.random.PRNGKey(1337)\n",
        "\n",
        "model = BigramLanguageModel(vocab_size=vocab_size, block_size=block_size, embedding_size=n_embed)\n",
        "params = model.init(key, X)\n",
        "\n",
        "out = model.apply(params, X)\n",
        "print(out.shape)\n",
        "\n",
        "loss = bigram_loss(out, Y)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joSWKRn_Dwqv",
        "outputId": "79b2e79e-aca9-46dc-dceb-e2774f9652e3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 8, 65)\n",
            "4.1815968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "key = jax.random.PRNGKey(1337)\n",
        "key_init, key_shuffle = jax.random.split(key)\n",
        "\n",
        "model = BigramLanguageModel(vocab_size=vocab_size, block_size=block_size, embedding_size=n_embed)\n",
        "params = model.init(key, X)\n",
        "\n",
        "opt = optax.adam(1e-3)\n",
        "opt_state = opt.init(params)"
      ],
      "metadata": {
        "id": "Pfq-LkmKY_o5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in tqdm(range(10000)):\n",
        "    key_batch = jax.random.fold_in(key=key_shuffle, data=epoch)\n",
        "    X, Y = get_batch(key_batch)\n",
        "    params, opt_state, loss = train_step(model.apply, params, opt_state, X, Y)\n",
        "\n",
        "print(f\"\\n\\nLoss: {loss}\") # Loss: 2.5348286628723145"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d86pVbzglSjr",
        "outputId": "90cd4e85-4d0a-4c15-fa1a-8d3b04d4bac0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [02:47<00:00, 59.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Loss: 2.1977155208587646\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Z = jnp.zeros(shape=(1, block_size), dtype=jnp.int32)\n",
        "out = bigram_generate(model.apply, key_shuffle, Z, max_tokens=500)\n",
        "out = decode(out[0][block_size:].tolist())\n",
        "print(out)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6fHtIALituo",
        "outputId": "e40be002-5df1-4c82-f92a-e8518bd79d6d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sornt prities! fwthe. K:\n",
            "Go wof to, Lore Rouses fy whacueblo, he, kouk An\n",
            "OUNI HE of whind\n",
            "An\n",
            "Gaut bed tosal de,\n",
            "Wo SI\n",
            "Are fonow! meries to thince.\n",
            "S\n",
            "OSis herlin dey rif for ar bergnt his weaur thion thir gofueg, hish tur yow, meamy larat fowsw ith ist utll!\n",
            "Whyis se thall,\n",
            "Moomtnorn wimund jutall;\n",
            "I, Beir:\n",
            "Ald to yous serigat mo wrasto V:\n",
            "CoLOd\n",
            "Ane, to, naw, man yein the pen. An\n",
            "Imard thalalls thamche.\n",
            "\n",
            "DUKBENCICHERARICARKELOMWAREBAng.\n",
            "\n",
            "\n",
            "Mof Vofeas cen, tun I BGUfakn! mallovie chetawe gher, son\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x6mQWBChCVP6"
      },
      "execution_count": 102,
      "outputs": []
    }
  ]
}